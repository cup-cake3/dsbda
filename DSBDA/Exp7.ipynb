{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cdd96859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02ad9690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46429f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecf7d4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39d4c73b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hi my name is Ishan.', 'I am computers student.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"Hi my name is Ishan. I am computers student.\"\n",
    "token=nltk.sent_tokenize(sentence)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b4d6a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hallo', 'my', 'name', 'is', 'ishan', '.', 'What', \"'s\", 'yours', '?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words=\"Hallo my name is ishan. What's yours?\"\n",
    "token=nltk.word_tokenize(words)\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbd86efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85bdeef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4240e462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hallo', 'NNP'),\n",
       " ('my', 'PRP$'),\n",
       " ('name', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('ishan', 'JJ'),\n",
       " ('.', '.'),\n",
       " ('What', 'WP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('yours', 'JJR'),\n",
       " ('?', '.')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b3d9e940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36dd61e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcad4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f195e0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['This', 'is', 'a', 'sample', 'sentence', ',', 'showing', 'off', 'stop', 'words', 'filteration', '.']\n",
      "stop word removed: ['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filteration', '.']\n"
     ]
    }
   ],
   "source": [
    "example=\"This is a sample sentence, showing off stop words filteration.\"\n",
    "stop_words=set(stopwords.words('english'))\n",
    "word_tokens=word_tokenize(example)\n",
    "\n",
    "l=[]\n",
    "for w in word_tokens:\n",
    "    if w not in stop_words:\n",
    "        l.append(w)\n",
    "\n",
    "print(\"tokens:\",word_tokens)\n",
    "print(\"stop word removed:\",l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a53878f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: ishan,stem: ishan\n",
      "Actual: says,stem: say\n",
      "Actual: he,stem: he\n",
      "Actual: would,stem: would\n",
      "Actual: be,stem: be\n",
      "Actual: studying,stem: studi\n",
      "Actual: but,stem: but\n",
      "Actual: is,stem: is\n",
      "Actual: busy,stem: busi\n",
      "Actual: admiring,stem: admir\n",
      "Actual: sakushi,stem: sakushi\n",
      "Actual: 's,stem: 's\n",
      "Actual: immaculate,stem: immacul\n",
      "Actual: beauty,stem: beauti\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemming=PorterStemmer()\n",
    "word=\"ishan says he would be studying but is busy admiring sakushi's immaculate beauty\"\n",
    "token=word_tokenize(word)\n",
    "for w in token:\n",
    "    print(f\"Actual: {w},stem: {stemming.stem(w)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8ef35b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: ishan,  lemma: ishan\n",
      "Actual: says,  lemma: say\n",
      "Actual: he,  lemma: he\n",
      "Actual: would,  lemma: would\n",
      "Actual: be,  lemma: be\n",
      "Actual: studying,  lemma: studying\n",
      "Actual: but,  lemma: but\n",
      "Actual: is,  lemma: is\n",
      "Actual: busy,  lemma: busy\n",
      "Actual: admiring,  lemma: admiring\n",
      "Actual: sakushi,  lemma: sakushi\n",
      "Actual: 's,  lemma: 's\n",
      "Actual: immaculate,  lemma: immaculate\n",
      "Actual: beauty,  lemma: beauty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ishan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma=WordNetLemmatizer()\n",
    "for w in token:\n",
    "    print(f\"Actual: {w},  lemma: {lemma.lemmatize(w)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "38abc87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0cf506fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job', 'Science', '21st', 'Data', 'science', 'Machine', 'key', 'of', 'best', 'for', 'data', 'century', 'is', 'the', 'learning'}\n"
     ]
    }
   ],
   "source": [
    "first=\"Data Science is the best job of 21st century\"\n",
    "second=\"Machine learning is the key for data science\"\n",
    "\n",
    "firstSen=first.split(\" \")\n",
    "secondSen=second.split(\" \")\n",
    "\n",
    "final=set(firstSen).union(set(secondSen))\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b225262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>Science</th>\n",
       "      <th>21st</th>\n",
       "      <th>Data</th>\n",
       "      <th>science</th>\n",
       "      <th>Machine</th>\n",
       "      <th>key</th>\n",
       "      <th>of</th>\n",
       "      <th>best</th>\n",
       "      <th>for</th>\n",
       "      <th>data</th>\n",
       "      <th>century</th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "      <th>learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job  Science  21st  Data  science  Machine  key  of  best  for  data  \\\n",
       "0    1        1     1     1        0        0    0   1     1    0     0   \n",
       "1    0        0     0     0        1        1    1   0     0    1     1   \n",
       "\n",
       "   century  is  the  learning  \n",
       "0        1   1    1         0  \n",
       "1        0   1    1         1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictA=dict.fromkeys(final,0)\n",
    "dictB=dict.fromkeys(final,0)\n",
    "\n",
    "for w in firstSen:\n",
    "    dictA[w]+=1\n",
    "    \n",
    "for w in secondSen:\n",
    "    dictB[w]+=1\n",
    "    \n",
    "pd.DataFrame([dictA,dictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6cdd0bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>Science</th>\n",
       "      <th>21st</th>\n",
       "      <th>Data</th>\n",
       "      <th>science</th>\n",
       "      <th>Machine</th>\n",
       "      <th>key</th>\n",
       "      <th>of</th>\n",
       "      <th>best</th>\n",
       "      <th>for</th>\n",
       "      <th>data</th>\n",
       "      <th>century</th>\n",
       "      <th>is</th>\n",
       "      <th>the</th>\n",
       "      <th>learning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        job   Science      21st      Data  science  Machine    key        of  \\\n",
       "0  0.111111  0.111111  0.111111  0.111111    0.000    0.000  0.000  0.111111   \n",
       "1  0.000000  0.000000  0.000000  0.000000    0.125    0.125  0.125  0.000000   \n",
       "\n",
       "       best    for   data   century        is       the  learning  \n",
       "0  0.111111  0.000  0.000  0.111111  0.111111  0.111111     0.000  \n",
       "1  0.000000  0.125  0.125  0.000000  0.125000  0.125000     0.125  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TF\n",
    "def TF(words,doc):\n",
    "    d={}\n",
    "    corpusCount=len(doc)\n",
    "    for w,c in words.items():\n",
    "        d[w]=c/float(corpusCount)\n",
    "    return(d)\n",
    "tfFirst=TF(dictA,firstSen)\n",
    "tfSecond=TF(dictB,secondSen)\n",
    "pd.DataFrame([tfFirst,tfSecond])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6245fbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IDF\n",
    "\n",
    "def IDF(doc):\n",
    "    d={}\n",
    "    count=len(doc)\n",
    "    d=dict.fromkeys(doc[0].keys(),0)\n",
    "    for w,val in d.items():\n",
    "        d[w]=math.log10(count/(float(val)+1))\n",
    "    return d\n",
    "idfs=IDF([dictA,dictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a6add658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job': 0.3010299956639812,\n",
       " 'Science': 0.3010299956639812,\n",
       " '21st': 0.3010299956639812,\n",
       " 'Data': 0.3010299956639812,\n",
       " 'science': 0.3010299956639812,\n",
       " 'Machine': 0.3010299956639812,\n",
       " 'key': 0.3010299956639812,\n",
       " 'of': 0.3010299956639812,\n",
       " 'best': 0.3010299956639812,\n",
       " 'for': 0.3010299956639812,\n",
       " 'data': 0.3010299956639812,\n",
       " 'century': 0.3010299956639812,\n",
       " 'is': 0.3010299956639812,\n",
       " 'the': 0.3010299956639812,\n",
       " 'learning': 0.3010299956639812}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "30da4df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        job\n",
       "0  0.033448\n",
       "1  0.000000"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "        return(tfidf)\n",
    "#running our two sentences through the IDF:\n",
    "idfFirst = computeTFIDF(tfFirst, idfs)\n",
    "idfSecond = computeTFIDF(tfSecond, idfs)\n",
    "#putting it in a dataframe\n",
    "pd.DataFrame([idfFirst, idfSecond])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74620314",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
